{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 35px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Nuclear Incidents\n",
    "  </div> \n",
    "\n",
    "  \n",
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 25px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "      Data Preparation\n",
    "  </div> \n",
    "\n",
    "\n",
    "  <div style=\" float:left; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> \n",
    "  \n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  Jan 2023\n",
    "  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"TOC\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<div style=\"font-weight: normal; \n",
    "      font-size: 25px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "      Table of Content\n",
    "  </div> \n",
    "\n",
    "1. [Corpus Import](#corpus)\n",
    "2. [Metadata Extraction](#metadata)\n",
    "3. [Text Segmentation](#segmentation)\n",
    "\n",
    "\n",
    "\n",
    "[Bottom](#bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbaujogue\\AppData\\Local\\Temp\\ipykernel_6640\\2593984787.py:21: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import unicodedata\n",
    "import re\n",
    "import copy\n",
    "from unidecode import unidecode\n",
    "from ast import literal_eval # transforms back stings into list of words\n",
    "\n",
    "# for data \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for nlp\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as en_stop\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "\n",
    "# for visualization\n",
    "from IPython.core.display import display, HTML\n",
    "from tqdm import tnrange\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('python version :', sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_repo = os.path.dirname(os.getcwd())\n",
    "path_to_data = os.path.join(path_to_repo, 'data')\n",
    "path_to_save = os.path.join(path_to_repo, 'saves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(path_to_repo, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmtools.tfidf import compute_gensim_tfidf_similarity_matrix\n",
    "from tmtools.span import get_maximal_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spacy.pipeline.functions.merge_entities(doc: spacy.tokens.doc.Doc)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load relevant nlp models:\n",
    "\n",
    "# 450 MB transformer-based model\n",
    "nlp_en = spacy.load('en_core_web_trf')\n",
    "\n",
    "# Merge multi-word entities into single tokens\n",
    "nlp_en.add_pipe(\"merge_entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400 MB transformer-based model\n",
    "nlp = spacy.load('fr_dep_news_trf', disable = ['ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corpus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Corpus Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incidents = pd.read_excel(os.path.join(path_to_data, 'data_nuclear_incidents.xlsx'))\n",
    "df_incidents = df_incidents[['text']]\n",
    "df_incidents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non-respect d’une règle de maîtrise de la crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-respect des spécifications techniques d’ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Non-respect d’une règle de maîtrise de la crit...\n",
       "1  Non-respect des spécifications techniques d’ex..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incidents.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"metadata\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Metadata Extraction\n",
    "\n",
    "[Table of content](#TOC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents['Doc_id'] = df_incidents.index.tolist()\n",
    "df_incidents['title']  = df_incidents['text'].apply(lambda t: t.split('\\n')[0])\n",
    "df_incidents['text']   = df_incidents['text'].apply(lambda t: '\\n'.join(t.split('\\n')[1:]))\n",
    "\n",
    "df_incidents = df_incidents[['Doc_id', 'text', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>La société Framatome a déclaré le 20 avril 202...</td>\n",
       "      <td>Non-respect d’une règle de maîtrise de la crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Le 7 avril 2021, l’exploitant de la centrale n...</td>\n",
       "      <td>Non-respect des spécifications techniques d’ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_id                                               text  \\\n",
       "0       0  La société Framatome a déclaré le 20 avril 202...   \n",
       "1       1  Le 7 avril 2021, l’exploitant de la centrale n...   \n",
       "\n",
       "                                               title  \n",
       "0  Non-respect d’une règle de maîtrise de la crit...  \n",
       "1  Non-respect des spécifications techniques d’ex...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incidents.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find dates and locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Le 7 avril 2021\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", l’exploitant de la centrale nucléaire de Belleville-sur-Loire a déclaré à l’ASN un événement significatif pour la sûreté relatif à la découverte tardive de l’indisponibilité d’un système contribuant au refroidissement du cœur du réacteur.</br>Chaque réacteur dispose d’un circuit d’injection de sécurité (RIS). Ce circuit permet notamment, en cas d'accident lié à une brèche au niveau du circuit primaire du réacteur, d'introduire de l'eau borée sous pression dans celui-ci et d’assurer ainsi le refroidissement du cœur du réacteur. Ce circuit comporte plusieurs pompes haute et basse pression. </br>\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Le 20 juillet 2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", dans le cadre d’un essai périodique d’une pompe du circuit RIS du réacteur 2, l’exploitant a détecté une élévation de température de cette pompe par rapport au dernier essai réalisé \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    le 3 novembre 2019\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". A ce stade de l’analyse, la disponibilité de la pompe n’a pas été remise en cause par l’exploitant, les résultats de l’essai ayant respecté les règles générales d’exploitation. Des investigations complémentaires ont néanmoins été lancées pour comprendre l’origine de cette élévation de température.</br>\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Le 2 avril 2021\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", après une analyse approfondie, l’exploitant a identifié que le fonctionnement de la pompe incriminée pouvait, dans certaines conditions accidentelles, ne plus être assuré. La fonction de refroidissement du cœur associée au circuit RIS a donc été considérée comme partiellement indisponible. Cette fonction aurait néanmoins pu être assurée par d’autres pompes du circuit RIS.</br>Les spécifications techniques d’exploitation requièrent la disponibilité complète du circuit RIS dès le redémarrage du réacteur, soit à \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    partir de novembre 2019\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". Elles imposent également le repli du réacteur dans un état plus sûr sous 3 jours lorsqu’une pompe est indisponible. Du fait de la prise en compte tardive de l’indisponibilité partielle de la fonction de refroidissement, les spécifications techniques d’exploitation n’ont pas été respectées.</br>Cet événement n’a pas eu de conséquence sur les installations, les personnes et l’environnement. Toutefois, l’événement a affecté la fonction de sûreté liée au refroidissement du réacteur 2. En raison de l’indisponibilité partielle mais prolongée d’un système de sûreté et du non-respect des spécifications techniques d’exploitation, cet événement a été classé au niveau 1 de l’échelle INES (échelle internationale des événements nucléaires et radiologiques, graduée de 0 à 7 par ordre croissant de gravité).</br>Une intervention a été rapidement engagée par l’exploitant du \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CNPE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " afin de retrouver la disponibilité totale de la pompe concernée. La pompe a été rendue disponible \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    le 4 avril 2021\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". L’ASN sera attentive aux actions correctives prises par l’exploitant pour détecter plus rapidement ce type d’indisponibilité.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# an example\n",
    "text = df_incidents.text[1]\n",
    "doc = nlp_en(text)\n",
    "\n",
    "spacy.displacy.render(doc, style = \"ent\", jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df_incidents['title'].tolist()\n",
    "texts  = df_incidents.text.tolist()\n",
    "\n",
    "common_entities = []\n",
    "for i in tnrange(len(texts)):\n",
    "    title = titles[i]\n",
    "    text = texts[i]\n",
    "    ents = nlp_en(title + '\\n' + text).ents\n",
    "    common_entities.append(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [[ent.text for ent in ents if ent.label_ == 'DATE'] for ents in common_entities]\n",
    "dates = [ds[0].replace('2021à', '2021') if len(ds)>0 else None for ds in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents['date'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [[ent for ent in ents if ent.label_ == 'GPE'] for ents in common_entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_locations = [loc.text for locs in locations for loc in locs]\n",
    "unique_locations += ['Saint-Laurent-des-Eaux']\n",
    "unique_locations = set(unique_locations)\n",
    "unique_locations - set(['Areva NC', 'Aucun', 'Saint'])\n",
    "unique_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infered_locations = [[(loc, text.count(loc)) for loc in unique_locations] for text in df_incidents.text]\n",
    "infered_locations = [sorted(locs, key = lambda lc: lc[1], reverse = True)[0] for locs in infered_locations]\n",
    "infered_locations = [lc[0] if lc[1]>0 else 'Inconnu' for lc in infered_locations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([loc for loc in infered_locations if loc == 'Inconnu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infered_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents['location'] = infered_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents = df_incidents[['Doc_id', 'title', 'date', 'location', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents.to_excel(os.path.join(path_to_data, 'source_texts.xlsx'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segmentation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text segmentation\n",
    "\n",
    "[Table of Content](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents = pd.read_excel(os.path.join(path_to_data, 'source_texts.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Non-respect d’une règle de maîtrise de la crit...</td>\n",
       "      <td>le 20 avril 2021</td>\n",
       "      <td>Romans-sur-Isère</td>\n",
       "      <td>La société Framatome a déclaré le 20 avril 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Non-respect des spécifications techniques d’ex...</td>\n",
       "      <td>Le 7 avril 2021</td>\n",
       "      <td>Belleville-sur-Loire</td>\n",
       "      <td>Le 7 avril 2021, l’exploitant de la centrale n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Non-respect d’une consigne de maîtrise de la c...</td>\n",
       "      <td>le 13 avril 2021</td>\n",
       "      <td>Romans-sur-Isère</td>\n",
       "      <td>La société Framatome a déclaré le 13 avril 202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_id                                              title  \\\n",
       "0       0  Non-respect d’une règle de maîtrise de la crit...   \n",
       "1       1  Non-respect des spécifications techniques d’ex...   \n",
       "2       2  Non-respect d’une consigne de maîtrise de la c...   \n",
       "\n",
       "               date              location  \\\n",
       "0  le 20 avril 2021      Romans-sur-Isère   \n",
       "1   Le 7 avril 2021  Belleville-sur-Loire   \n",
       "2  le 13 avril 2021      Romans-sur-Isère   \n",
       "\n",
       "                                                text  \n",
       "0  La société Framatome a déclaré le 20 avril 202...  \n",
       "1  Le 7 avril 2021, l’exploitant de la centrale n...  \n",
       "2  La société Framatome a déclaré le 13 avril 202...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incidents.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Segmentation into paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = df_incidents.apply(\n",
    "    func = lambda r: [(r.Doc_id, i, r.title, r.date, r.location, p) for i, p in enumerate(re.sub('(\\n)+', '\\n', r.text).split('\\n'))],\n",
    "    axis = 1,\n",
    ")\n",
    "paragraphs = [p for ps in paragraphs for p in ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10210, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragraphs = pd.DataFrame(paragraphs, columns = ['Doc_id', 'Para_id', 'title', 'date', 'location', 'text'])\n",
    "df_paragraphs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs.to_excel(os.path.join(path_to_data, 'source_paragraphs.xlsx'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Segmentation into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PunktSentenceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_paragraphs.apply(\n",
    "    func = lambda r: [(r.Doc_id, r.Para_id, i, r.title, r.date, r.location, s) for i, s in enumerate(tokenizer.tokenize(r.text))],\n",
    "    axis = 1,\n",
    ")\n",
    "sentences = [s for ss in sentences for s in ss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18861, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences = pd.DataFrame(sentences, columns = ['Doc_id', 'Para_id', 'Sent_id', 'title', 'date', 'location', 'text'])\n",
    "df_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences.to_excel(os.path.join(path_to_data, 'source_sentences.xlsx'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Span extraction\n",
    "\n",
    "[Table of Content](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_data(s):\n",
    "    return (s.text, s.lemma_, s.root.lemma_, s.start, s.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = df_sentences.apply(\n",
    "    func = lambda r: [[r.Doc_id, r.Para_id, r.Sent_id, i, r.title, r.date, r.location] + list(get_span_data(s)) for i, s in enumerate(get_maximal_spans(nlp(r.text)))],\n",
    "    axis = 1,\n",
    ")\n",
    "spans = [s for ss in spans for s in ss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59864, 12)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spans = pd.DataFrame(spans, columns = [\n",
    "    'Doc_id', 'Para_id', 'Sent_id', 'Span_id', 'title', 'date', 'location', 'text', 'lemma', 'root', 'start', 'end',\n",
    "])\n",
    "df_spans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spans.to_excel(os.path.join(path_to_data, 'source_spans.xlsx'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bottom\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of content](#TOC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
